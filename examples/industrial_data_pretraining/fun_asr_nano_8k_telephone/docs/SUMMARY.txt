================================================================================
Fun-ASR-Nano 8kHz ç”µè¯è¯­éŸ³å¾®è°ƒ - å®éªŒæ‰§è¡Œæ€»ç»“
================================================================================

ğŸ“… æ—¥æœŸ: 2026-01-05
ğŸ“ ä½ç½®: /workspace/share/LLMFunASR/examples/industrial_data_pretraining/fun_asr_nano_8k_telephone/

================================================================================
âœ… å·²å®Œæˆä»»åŠ¡
================================================================================

1. é¡¹ç›®ç»“æ„å»ºç«‹
   âœ“ ä¸‰é˜¶æ®µå¾®è°ƒæ¡†æ¶æ­å»º
   âœ“ è„šæœ¬å’Œé…ç½®æ–‡ä»¶ç¼–å†™
   âœ“ æ–‡æ¡£ç³»ç»Ÿå®Œå–„

2. æ•°æ®å‡†å¤‡ (Stage 0) - 100% å®Œæˆ
   âœ“ WenetSpeech ç”µè¯ä¿¡é“æ¨¡æ‹Ÿ (65,170 â†’ 63,782 æœ‰æ•ˆæ ·æœ¬)
   âœ“ çœŸå®ç”µè¯æ•°æ®å¤„ç† (21,173 â†’ 16,677 æœ‰æ•ˆæ ·æœ¬)
   âœ“ æ•°æ®æ ¼å¼è½¬æ¢ (FunASR-Nano messagesæ ¼å¼)
   âœ“ è‡ªåŠ¨æ³¨é‡Šé”™è¯¯è¿‡æ»¤ (571+782 = 1,353 æ¡)
   âœ“ 8kHz â†’ 16kHz ä¸Šé‡‡æ · (ä¿ç•™å¤±çœŸç‰¹å¾)

3. è„šæœ¬å’Œå·¥å…·å¼€å‘
   âœ“ run_experiment.sh - ä¸‰é˜¶æ®µè®­ç»ƒä¸»è„šæœ¬
   âœ“ test_data_prep.sh - æ•°æ®å‡†å¤‡æµ‹è¯•è„šæœ¬  
   âœ“ data/data_simulation.py - å¢å¼ºç”µè¯ä¿¡é“æ¨¡æ‹Ÿ
   âœ“ data/prepare_training_data.py - å¢å¼ºæ•°æ®å‡†å¤‡å·¥å…·

4. æ–‡æ¡£ç¼–å†™
   âœ“ IMPLEMENTATION_PLAN.md - å®Œæ•´æŠ€æœ¯æ–¹æ¡ˆ
   âœ“ EXPERIMENT_EXECUTION_PLAN.md - è¯¦ç»†æ‰§è¡Œè®¡åˆ’
   âœ“ STAGE0_COMPLETION_REPORT.md - æ•°æ®å‡†å¤‡æŠ¥å‘Š
   âœ“ README_EXPERIMENT_STATUS.md - å®éªŒçŠ¶æ€æŠ¥å‘Š
   âœ“ QUICKSTART.md - å¿«é€Ÿå¼€å§‹æŒ‡å—
   âœ“ TRAINING_DATA_SPEC.md - æ•°æ®æ ¼å¼è§„èŒƒ

================================================================================
ğŸ“Š æ•°æ®ç»Ÿè®¡ç»“æœ
================================================================================

æ¨¡æ‹Ÿæ•°æ® (WenetSpeech æ¨¡æ‹Ÿç”µè¯):
  - è®­ç»ƒé›†: 63,782 samples
  - éªŒè¯é›†: 13,825 samples
  - æœ‰æ•ˆæ ·æœ¬: 77,607
  - è¿‡æ»¤æ ·æœ¬: 1,388 (é•¿åº¦è¿‡é•¿)
  - è·¯å¾„: exp_output/data/simulated_8k_telephone/

çœŸå®æ•°æ® (ç”µè¯å¤–å‘¼åœºæ™¯):
  - è®­ç»ƒé›†: 8,992 samples (è¿‡æ»¤å‰ 12,172)
  - éªŒè¯é›†: 7,685 samples (è¿‡æ»¤å‰ 9,001)
  - æœ‰æ•ˆæ ·æœ¬: 16,677
  - æ³¨é‡Šé”™è¯¯: 1,353 (å·²è¿‡æ»¤)
  - è¿‡æ»¤æ ·æœ¬: 3,143 (é•¿åº¦ä¸ç¬¦)
  - è·¯å¾„: exp_output/data/real_8k_telephone/

æ€»è®¡: 94,284 æœ‰æ•ˆæ ·æœ¬

================================================================================
ğŸ¯ ä¸‰é˜¶æ®µå¾®è°ƒæ–¹æ¡ˆ
================================================================================

Stage 1: Audio Encoder é€‚é…
  - å¯è®­ç»ƒå‚æ•°: ~150M (å…¨é‡Encoder)
  - å†»ç»“æ¨¡å—: Adaptor, CTC, LLM
  - å­¦ä¹ ç‡: 1e-4
  - æ•°æ®: 63.7k æ¨¡æ‹Ÿæ ·æœ¬
  - é¢„è®¡æ—¶é—´: 2-3 å¤© (2x H100)
  - ç›®æ ‡: Encoder å­¦ä¹  8kHz é¢‘è°±ç‰¹å¾

Stage 2: Adapter & CTC å¯¹é½
  - å¯è®­ç»ƒå‚æ•°: ~12M (Adaptor + CTC)
  - å†»ç»“æ¨¡å—: Encoder (S1), LLM
  - å­¦ä¹ ç‡: 5e-5
  - æ•°æ®: 63.7k æ¨¡æ‹Ÿæ ·æœ¬
  - é¢„è®¡æ—¶é—´: 2-3 å¤©
  - ç›®æ ‡: 8kHz ç‰¹å¾é‡æ–°æ˜ å°„åˆ°Tokenç©ºé—´

Stage 3: LLM LoRA ä¸šåŠ¡é€‚é…
  - å¯è®­ç»ƒå‚æ•°: ~2M (LoRA r=16)
  - å†»ç»“æ¨¡å—: Encoder, Adaptor, CTC
  - å­¦ä¹ ç‡: 1e-5
  - æ•°æ®: 8.9k çœŸå®ç”µè¯æ•°æ®
  - é¢„è®¡æ—¶é—´: 1-2 å¤©
  - ç›®æ ‡: æ³¨å…¥ä¸šåŠ¡æœ¯è¯­å’Œåœºæ™¯ä¿¡æ¯

================================================================================
âš ï¸ å·²è¯†åˆ«é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ
================================================================================

Problem 1: WavFrontend ä½ç½®ç¼–ç ç»´åº¦ä¸åŒ¹é…
  ç—‡çŠ¶: RuntimeError: tensor dimension mismatch
  åŸå› : 8kHz ä¸Šé‡‡æ ·è‡³ 16kHz å¯¼è‡´æ—¶é—´åºåˆ—é•¿åº¦å˜åŒ–
  è§£å†³: ä¿®æ”¹ conf/stage1_encoder_adapt.yaml
    - frontend.fs: 16000 â†’ 8000
    - dataset_conf.max_token_length: 8000 â†’ 10000

Problem 2: æ¨¡å‹åˆå§‹åŒ–è·¯å¾„ä¸å­˜åœ¨
  ç—‡çŠ¶: init_param does not exist
  åŸå› : MODELSCOPE_CACHE è·¯å¾„ä¸ç»Ÿä¸€
  è§£å†³: 
    æ–¹æ¡ˆA: python -c "from modelscope import snapshot_download; ..."
    æ–¹æ¡ˆB: åœ¨ run_experiment.sh ä¸­æŒ‡å®šæ­£ç¡®è·¯å¾„

Problem 3: æ•°æ®æ ·æœ¬è¿‡æ»¤æ¯”ä¾‹è¾ƒé«˜
  ç°è±¡: 1,388/65,170 (2.1%) åœ¨æ¨¡æ‹Ÿæ•°æ®ä¸­è¿‡æ»¤
  åŸå› : max_speech_length=8000 é™åˆ¶
  æ”¹è¿›: 
    - è°ƒæ•´é˜ˆå€¼è‡³ 12000
    - æˆ–ä½¿ç”¨ç™¾åˆ†ä½æ•°è‡ªé€‚åº”è¿‡æ»¤

================================================================================
ğŸ“‚ å…³é”®æ–‡ä»¶ä½ç½®
================================================================================

è„šæœ¬:
  /workspace/share/LLMFunASR/examples/industrial_data_pretraining/fun_asr_nano_8k_telephone/
  â”œâ”€â”€ run_experiment.sh              (ä¸»å®éªŒè„šæœ¬)
  â”œâ”€â”€ test_data_prep.sh              (æ•°æ®æµ‹è¯•è„šæœ¬)
  â”œâ”€â”€ data/data_simulation.py        (ç”µè¯ä¿¡é“æ¨¡æ‹Ÿ)
  â”œâ”€â”€ data/prepare_training_data.py  (æ•°æ®æ ¼å¼è½¬æ¢)
  â””â”€â”€ conf/
      â”œâ”€â”€ stage1_encoder_adapt.yaml  (âš ï¸ éœ€ä¿®å¤)
      â”œâ”€â”€ stage2_adapter_align.yaml
      â””â”€â”€ stage3_lora_domain.yaml

æ•°æ®:
  /workspace/share/LLMFunASR/examples/industrial_data_pretraining/fun_asr_nano_8k_telephone/
  â””â”€â”€ exp_output/data/
      â”œâ”€â”€ simulated_8k_telephone/
      â”‚   â”œâ”€â”€ train_formatted.jsonl   (63,782 samples)
      â”‚   â”œâ”€â”€ dev_formatted.jsonl     (13,825 samples)
      â”‚   â””â”€â”€ audio/
      â””â”€â”€ real_8k_telephone/
          â”œâ”€â”€ train_formatted.jsonl   (8,992 samples)
          â”œâ”€â”€ dev_formatted.jsonl     (7,685 samples)
          â””â”€â”€ audio_upsampled/

æ–‡æ¡£:
  â”œâ”€â”€ README_EXPERIMENT_STATUS.md    (ğŸ‘ˆ å®æ—¶çŠ¶æ€)
  â”œâ”€â”€ STAGE0_COMPLETION_REPORT.md    (æ•°æ®å‡†å¤‡è¯¦æƒ…)
  â”œâ”€â”€ IMPLEMENTATION_PLAN.md         (æŠ€æœ¯æ–¹æ¡ˆ)
  â”œâ”€â”€ EXPERIMENT_EXECUTION_PLAN.md   (æ‰§è¡Œè®¡åˆ’)
  â”œâ”€â”€ QUICKSTART.md                  (å¿«é€Ÿå¼€å§‹)
  â””â”€â”€ TRAINING_DATA_SPEC.md          (æ•°æ®è§„èŒƒ)

================================================================================
ğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨
================================================================================

ç«‹å³æ‰§è¡Œ (1-2 å°æ—¶):
  1. ä¿®å¤ WavFrontend é…ç½®
     ç¼–è¾‘: conf/stage1_encoder_adapt.yaml
     æ”¹å˜: frontend.fs 16000 â†’ 8000
  
  2. éªŒè¯æ¨¡å‹è·¯å¾„
     æ£€æŸ¥: Fun-ASR-Nano-2512 çš„å®é™…ä½ç½®
     æ›´æ–°: run_experiment.sh ä¸­çš„ ptm_checkpoint

  3. éªŒè¯æ•°æ®å®Œæ•´æ€§
     æ£€æŸ¥: exp_output/data/ ä¸‹çš„æ–‡ä»¶å¤§å°å’Œæ•°é‡

å‡†å¤‡æ‰§è¡Œ (å¾…é…ç½®ä¿®å¤):
  4. å¯åŠ¨ Stage 1 è®­ç»ƒ
     å‘½ä»¤: bash run_experiment.sh 1 1
     ç›‘æ§: tail -f exp_output/exp/8k_telephone/*/train.log

åç»­æ‰§è¡Œ:
  5. ç›‘æ§ Stage 1 æŒ‡æ ‡
     - Loss ä¸‹é™è¶‹åŠ¿ (ç›®æ ‡: 30%+ ä¸‹é™)
     - CER æ”¹å–„æƒ…å†µ
     - GPU æ˜¾å­˜ä½¿ç”¨
  
  6. Stage 2 & 3 è®­ç»ƒ
     æŒ‰é¡ºåºæ‰§è¡Œ Stage 2 å’Œ Stage 3

  7. è¯„ä¼°å’ŒæŠ¥å‘Š
     - å…³é”®è¯å‡†ç¡®ç‡ (KWER)
     - æ•´ä½“ CER/WER
     - ä¸šåŠ¡åœºæ™¯æ•ˆæœ

================================================================================
ğŸ“ å®éªŒæ”¯æŒ
================================================================================

ä¸»è¦è”ç³»äºº:
  Algorithm Research Team

æ ¸å¿ƒè„šæœ¬å¸®åŠ©:
  bash run_experiment.sh            # æŸ¥çœ‹ä½¿ç”¨æ–¹æ³•
  bash test_data_prep.sh            # å°è§„æ¨¡æµ‹è¯•

æ—¥å¿—ç›‘æ§:
  tail -f exp_output/exp/8k_telephone/*/train.log
  watch -n 5 'nvidia-smi'

æ–‡æ¡£å¯¼èˆª:
  å¿«é€Ÿå¼€å§‹    â†’ QUICKSTART.md
  æŠ€æœ¯ç»†èŠ‚    â†’ IMPLEMENTATION_PLAN.md
  å®æ—¶çŠ¶æ€    â†’ README_EXPERIMENT_STATUS.md
  æ•°æ®å‡†å¤‡    â†’ STAGE0_COMPLETION_REPORT.md

================================================================================
âœ¨ å®éªŒäº®ç‚¹
================================================================================

âœ“ å®Œæ•´çš„ä¸‰é˜¶æ®µå¾®è°ƒæ¡†æ¶
âœ“ çœŸå®ç”µè¯æ•°æ® + æ¨¡æ‹Ÿæ•°æ®æ··åˆè®­ç»ƒ
âœ“ è‡ªåŠ¨åŒ–æ•°æ®å‡†å¤‡å’ŒéªŒè¯å·¥å…·
âœ“ è¯¦ç»†çš„æ–‡æ¡£å’Œé”™è¯¯è¯Šæ–­
âœ“ å¯å¤ç°çš„å®éªŒæµç¨‹

================================================================================
å®éªŒçŠ¶æ€: ğŸŸ¢ æŒ‰è®¡åˆ’è¿›è¡Œ

å½“å‰é˜¶æ®µ: Stage 0 (æ•°æ®å‡†å¤‡) âœ… å®Œæˆ
ä¸‹ä¸€é˜¶æ®µ: Stage 1 (Encoder å¾®è°ƒ) â³ å¾…å¯åŠ¨

æ€»ä½“è¿›åº¦: 12.5% (1/8 å‘¨)

================================================================================
