# Copyright FunASR (https://github.com/alibaba-damo-academy/FunASR). All Rights Reserved.
#  MIT License  (https://opensource.org/licenses/MIT)

# Configuration file for Fun-ASR-Nano 8kHz telephone channel fine-tuning
# This configuration matches the Fun-ASR-Nano-2512 model architecture
# Note: Audio is upsampled from 8kHz to 16kHz to work with WavFrontend

# Network architecture
# For training from scratch or fine-tuning with custom config, uncomment model_conf:
model: FunASRNano
model_conf:
    lsm_weight: 0.1  # Label smoothing
    length_normalized_loss: true

# For loading pretrained model from hub, use one of these:
# model: FunAudioLLM/Fun-ASR-Nano-2512  # Download from ModelScope
# hub: ms  # Use ModelScope hub (default)
# or
# model: FunAudioLLM/Fun-ASR-Nano-2512  # Download from HuggingFace
# hub: hf  # Use HuggingFace hub

# Audio Encoder Configuration
# Using SenseVoiceEncoderSmall (not Whisper)
audio_encoder: SenseVoiceEncoderSmall
audio_encoder_conf:
    output_size: 512
    attention_heads: 4
    linear_units: 2048
    num_blocks: 50
    tp_blocks: 20
    freeze: true

# LLM Configuration
# Using Qwen3-0.6B (not Qwen2.5-1.5B)
llm: Qwen3-0.6b
llm_conf:
    hub: hf
    freeze: true
    llm_dtype: bf16
    init_param_path: Qwen3-0.6B

# Audio Adaptor Configuration
# Using Transformer (not Linear)
audio_adaptor: Transformer
audio_adaptor_conf:
    downsample_rate: 1
    use_low_frame_rate: true
    ffn_dim: 2048
    llm_dim: 1024
    encoder_dim: 512
    n_layer: 2
    freeze: true

# CTC Decoder Configuration (Fun-ASR-Nano specific)
# This is the main trainable component for 8kHz telephone fine-tuning
ctc_decoder: Transformer
ctc_decoder_conf:
    downsample_rate: 1
    ffn_dim: 2048
    llm_dim: 512
    encoder_dim: 512
    n_layer: 5
    freeze: false
ctc_weight: 1.0

# Frontend Configuration
# Using WavFrontend (not WhisperFrontend)
# Note: WavFrontend requires 16kHz input
frontend: WavFrontend
frontend_conf:
    fs: 16000  # 16kHz (telephone audio upsampled from 8kHz to 16kHz)
    window: hamming
    n_mels: 80
    frame_length: 25
    frame_shift: 10
    lfr_m: 7
    lfr_n: 6

# SpecAug Configuration
specaug: SpecAugLFR
specaug_conf:
    apply_time_warp: false
    time_warp_window: 5
    time_warp_mode: bicubic
    apply_freq_mask: true
    freq_mask_width_range:
        - 0
        - 15  # Reduced from 30 for telephone audio
    lfr_rate: 6
    num_freq_mask: 1
    apply_time_mask: true
    time_mask_width_range:
        - 0
        - 10  # Slightly reduced for telephone scenarios
    num_time_mask: 1

# Training Configuration
train_conf:
    accum_grad: 1  # Gradient accumulation steps
    grad_clip: 5  # Gradient clipping
    max_epoch: 20  # More epochs for fine-tuning
    keep_nbest_models: 10
    log_interval: 10
    use_deepspeed: false  # Set to true when using DeepSpeed
    deepspeed_config: null  # Path to DeepSpeed config

# Optimizer Configuration
# Lower learning rate to preserve pre-trained knowledge
optim: adamw
optim_conf:
    lr: 0.00005  # 5e-5, lower learning rate for fine-tuning
    weight_decay: 0.01
    betas:
        - 0.9
        - 0.999

# Learning Rate Scheduler
scheduler: warmuplr
scheduler_conf:
    warmup_steps: 1000  # Gradual warmup

# Dataset Configuration
# Using FunASR dataset (not AudioLLMQwenAudioDataset)
dataset: FunASR
dataset_conf:
    index_ds: FunASR
    batch_sampler: BatchSampler
    batch_type: token
    batch_size: 6000  # Token-based batching
    max_token_length: 1024
    shuffle: true
    sort_size: 1024
    batch_size_scale_ratio_max: 2
    num_workers: 4
    audio_adaptor_downsample_rate: ${audio_adaptor_conf.downsample_rate}
    audio_encoder_downsample_rate: 2
    data_split_num: 512
    batch_size_sample_max: 15
    retry: 20

# Tokenizer Configuration
tokenizer: HuggingfaceTokenizer
tokenizer_conf:
    unk_symbol: <unk>
    init_param_path: Qwen3-0.6B

# Notes for 8kHz telephone fine-tuning:
# 1. Audio is upsampled from 8kHz to 16kHz to work with WavFrontend
# 2. Telephone channel characteristics are preserved during upsampling
# 3. Only CTC decoder is trainable (freeze: false), other components frozen
# 4. This approach adapts the model to 8kHz telephone domain via CTC decoder
# 5. Data simulation: 16kHz → 8kHz (telephone effects) → 16kHz (upsample)
# 6. Inference: 8kHz input → 16kHz (upsample) → model inference
